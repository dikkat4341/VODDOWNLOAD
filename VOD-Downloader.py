import os, sys, time, random, glob, json, re
from urllib.parse import urlparse
from datetime import datetime

# PyInstaller iÃ§in sys.path dÃ¼zeltmesi
if getattr(sys, 'frozen', False):
    application_path = os.path.dirname(sys.executable)
else:
    application_path = os.path.dirname(os.path.abspath(__file__))

os.chdir(application_path)

# KÃ¼tÃ¼phane import denemeleri
try:
    import requests
except ImportError:
    print("âŒ 'requests' kÃ¼tÃ¼phanesi bulunamadÄ±!")
    print("LÃ¼tfen ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n: pip install requests")
    input("Ã‡Ä±kmak iÃ§in Enter...")
    sys.exit(1)

try:
    from tqdm import tqdm
except ImportError:
    print("âŒ 'tqdm' kÃ¼tÃ¼phanesi bulunamadÄ±!")
    print("LÃ¼tfen ÅŸu komutu Ã§alÄ±ÅŸtÄ±rÄ±n: pip install tqdm")
    input("Ã‡Ä±kmak iÃ§in Enter...")
    sys.exit(1)

try:
    from concurrent.futures import ThreadPoolExecutor, as_completed
except ImportError:
    print("âŒ Python 3.2+ gerekli!")
    input("Ã‡Ä±kmak iÃ§in Enter...")
    sys.exit(1)

# --- YAPILANDIRMA ---
ua_file = 'user_agents.txt'
proxy_cache_file = 'turkey_proxies_cache.json'
MAX_RETRIES = 30
DOWNLOAD_DIR_DEFAULT = "Downloads"
MIN_PROXY_COUNT = 30

# Proxy yapÄ±landÄ±rmasÄ±
PROXY_POOL = []
PROXY_STATS = {}
PROXY_AUTO_ENABLED = True

# Ãœcretsiz TÃ¼rk Proxy API'leri
TURKEY_PROXY_SOURCES = [
    'https://api.proxyscrape.com/v2/?request=displayproxies&protocol=http&timeout=5000&country=TR&ssl=all&anonymity=all',
    'https://www.proxy-list.download/api/v1/get?type=http&country=TR',
    'https://raw.githubusercontent.com/TheSpeedX/PROXY-List/master/http.txt',
    'https://raw.githubusercontent.com/ShiftyTR/Proxy-List/master/http.txt',
    'https://raw.githubusercontent.com/monosans/proxy-list/main/proxies/http.txt',
]

def generate_random_ua():
    chrome_v = f"{random.randint(110, 125)}.0.{random.randint(1000, 6000)}.{random.randint(10, 150)}"
    return f"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{chrome_v} Safari/537.36"

def load_ua_pool(update=False):
    pool = []
    if not update and os.path.exists(ua_file):
        try:
            with open(ua_file, 'r', encoding='utf-8') as f:
                pool = [line.strip() for line in f if line.strip()]
        except Exception as e:
            print(f"âš ï¸ User-Agent dosyasÄ± okunamadÄ±: {e}")
    
    if len(pool) < 30 or update:
        pool = [generate_random_ua() for _ in range(40)]
        try:
            with open(ua_file, 'w', encoding='utf-8') as f:
                f.write('\n'.join(pool))
        except Exception as e:
            print(f"âš ï¸ User-Agent dosyasÄ± yazÄ±lamadÄ±: {e}")
    
    return pool if pool else [generate_random_ua() for _ in range(5)]

def check_proxy_location(proxy_url, timeout=8):
    """Proxy'nin lokasyonunu ve Ã§alÄ±ÅŸÄ±rlÄ±ÄŸÄ±nÄ± kontrol et"""
    proxies = {'http': proxy_url, 'https': proxy_url}
    
    try:
        response = requests.get('http://ip-api.com/json/', proxies=proxies, timeout=timeout)
        if response.status_code == 200:
            data = response.json()
            country = data.get('country', 'Unknown')
            country_code = data.get('countryCode', 'XX')
            ip = data.get('query', 'Unknown')
            
            is_turkey = country_code == 'TR'
            
            return {
                'working': True,
                'ip': ip,
                'country': country,
                'country_code': country_code,
                'is_turkey': is_turkey,
                'proxy': proxy_url,
                'response_time': response.elapsed.total_seconds()
            }
    except:
        pass
    
    return {'working': False, 'proxy': proxy_url}

def fetch_proxies_from_source(source_url):
    """Tek bir kaynaktan proxy listesi Ã§ek"""
    try:
        response = requests.get(source_url, timeout=15)
        if response.status_code == 200:
            proxies = re.findall(r'\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}:\d{2,5}', response.text)
            return [f'http://{p}' for p in proxies]
    except Exception as e:
        print(f"   âš ï¸ {source_url[:50]}... hatasÄ±: {e}")
    return []

def collect_turkey_proxies():
    """TÃ¼rk proxy'leri topla ve test et"""
    global PROXY_POOL
    
    print("\nğŸŒ TÃœRKÄ°YE PROXY HAVUZU OLUÅTURULUYOR...")
    print(f"ğŸ¯ Hedef: Minimum {MIN_PROXY_COUNT} aktif TÃ¼rk proxy")
    print("="*60)
    
    all_proxies = []
    
    # 1. Ã–nce cache'den yÃ¼kle
    if os.path.exists(proxy_cache_file):
        try:
            with open(proxy_cache_file, 'r') as f:
                cached = json.load(f)
                cache_age = time.time() - cached.get('timestamp', 0)
                
                if cache_age < 3600:
                    print(f"ğŸ“¦ Cache'den {len(cached.get('proxies', []))} proxy yÃ¼klendi (YaÅŸ: {int(cache_age/60)}dk)")
                    all_proxies.extend(cached.get('proxies', []))
        except:
            pass
    
    # 2. Yeni proxy'ler Ã§ek
    print("\nğŸ”„ Yeni proxy'ler aranÄ±yor...")
    for i, source in enumerate(TURKEY_PROXY_SOURCES, 1):
        print(f"[{i}/{len(TURKEY_PROXY_SOURCES)}] {source[:50]}...")
        proxies = fetch_proxies_from_source(source)
        all_proxies.extend(proxies)
        print(f"   âœ… {len(proxies)} proxy bulundu")
        time.sleep(0.5)
    
    all_proxies = list(set(all_proxies))
    print(f"\nğŸ“Š Toplam {len(all_proxies)} benzersiz proxy bulundu")
    
    # 3. Paralel test et
    print(f"\nğŸ§ª PROXY TEST EDÄ°LÄ°YOR (TÃ¼rkiye filtresi aktif)...")
    turkey_proxies = []
    
    with ThreadPoolExecutor(max_workers=20) as executor:
        future_to_proxy = {executor.submit(check_proxy_location, proxy): proxy for proxy in all_proxies}
        
        with tqdm(total=len(all_proxies), desc="Testing", unit="proxy") as pbar:
            for future in as_completed(future_to_proxy):
                result = future.result()
                pbar.update(1)
                
                if result['working'] and result.get('is_turkey', False):
                    turkey_proxies.append(result)
                    tqdm.write(f"âœ… TR Proxy: {result['ip']} ({result['response_time']:.2f}s)")
                    
                    if len(turkey_proxies) >= MIN_PROXY_COUNT:
                        print(f"\nğŸ‰ Hedef ulaÅŸÄ±ldÄ±! {len(turkey_proxies)} TÃ¼rk proxy aktif!")
                        executor.shutdown(wait=False, cancel_futures=True)
                        break
    
    turkey_proxies.sort(key=lambda x: x['response_time'])
    
    try:
        with open(proxy_cache_file, 'w') as f:
            json.dump({
                'timestamp': time.time(),
                'proxies': [p['proxy'] for p in turkey_proxies]
            }, f)
        print(f"ğŸ’¾ {len(turkey_proxies)} proxy cache'e kaydedildi")
    except:
        pass
    
    PROXY_POOL = turkey_proxies
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š SONUÃ‡ RAPORU")
    print(f"{'='*60}")
    print(f"âœ… Aktif TÃ¼rk Proxy: {len(turkey_proxies)}")
    if turkey_proxies:
        avg_time = sum(p['response_time'] for p in turkey_proxies) / len(turkey_proxies)
        print(f"âš¡ Ortalama YanÄ±t: {avg_time:.2f}s")
        print(f"ğŸš€ En HÄ±zlÄ±: {turkey_proxies[0]['ip']} ({turkey_proxies[0]['response_time']:.2f}s)")
    print(f"{'='*60}\n")
    
    return len(turkey_proxies) >= MIN_PROXY_COUNT

def get_random_working_proxy():
    """Rastgele Ã§alÄ±ÅŸan bir proxy al"""
    global PROXY_POOL
    
    if not PROXY_POOL:
        print("âš ï¸ Proxy havuzu boÅŸ! Yeniden oluÅŸturuluyor...")
        if not collect_turkey_proxies():
            print("âŒ Yeterli TÃ¼rk proxy bulunamadÄ±!")
            return None
    
    top_proxies = PROXY_POOL[:min(10, len(PROXY_POOL))]
    selected = random.choice(top_proxies)
    
    proxy_url = selected['proxy']
    if proxy_url not in PROXY_STATS:
        PROXY_STATS[proxy_url] = {'success': 0, 'fail': 0}
    
    return selected

def mark_proxy_result(proxy_url, success=True):
    """Proxy kullanÄ±m sonucunu kaydet"""
    global PROXY_POOL
    
    if proxy_url in PROXY_STATS:
        if success:
            PROXY_STATS[proxy_url]['success'] += 1
        else:
            PROXY_STATS[proxy_url]['fail'] += 1
            
            stats = PROXY_STATS[proxy_url]
            total = stats['success'] + stats['fail']
            if total >= 5 and stats['fail'] / total > 0.7:
                PROXY_POOL = [p for p in PROXY_POOL if p['proxy'] != proxy_url]
                print(f"ğŸ—‘ï¸ Proxy havuzdan Ã§Ä±karÄ±ldÄ±: {proxy_url[:50]}")
                
                if len(PROXY_POOL) < 10:
                    print("ğŸ”„ Proxy havuzu yenileniyor...")
                    collect_turkey_proxies()

def turkish_to_english_engine(text):
    """GeliÅŸmiÅŸ isim dÃ¼zeltme motoru."""
    name, ext = os.path.splitext(text)
    m = {
        'Ä±':'i','Ã¼':'u','ÄŸ':'g','Ã¶':'o','ÅŸ':'s','Ã§':'c',
        'Ä°':'I','Ãœ':'U','Ä':'G','Ã–':'O','Å':'S','Ã‡':'C',
        ' ':'_', '-':'_', '.':'_'
    }
    for tr, en in m.items():
        name = name.replace(tr, en)
    
    clean_name = re.sub(r'[^a-zA-Z0-9_]', '', name)
    clean_name = re.sub(r'_+', '_', clean_name).strip('_')
    
    return clean_name + ext.lower()

def check_m3u_info(url):
    if not url or url == '0': 
        return
    
    print("\nğŸ” XTREAM API SorgulanÄ±yor...")
    
    proxies = None
    if PROXY_AUTO_ENABLED and PROXY_POOL:
        proxy_info = get_random_working_proxy()
        if proxy_info:
            proxies = {'http': proxy_info['proxy'], 'https': proxy_info['proxy']}
            print(f"ğŸŒ TR Proxy: {proxy_info['ip']}")
    
    try:
        parsed = urlparse(url)
        base = f"{parsed.scheme}://{parsed.netloc}"
        params = dict(re.findall(r'(\w+)=([^&]+)', parsed.query))
        user, pw = params.get('username'), params.get('password')
        
        if not user or not pw:
            print("âš ï¸ URL Xtream formatÄ±nda deÄŸil.")
            return

        api_url = f"{base}/player_api.php?username={user}&password={pw}"
        r = requests.get(api_url, proxies=proxies, timeout=15)
        r.raise_for_status()
        data = r.json()
        
        if proxies:
            mark_proxy_result(proxies['http'], success=True)
        
        u_info = data.get('user_info', {})
        print(f"\n--- HESAP ANALÄ°ZÄ° ---")
        print(f"ğŸš¦ Durum: {u_info.get('status', 'Bilinmiyor')}")
        
        exp = u_info.get('exp_date')
        if exp and exp != "null":
            try:
                print(f"ğŸ“… BitiÅŸ: {datetime.fromtimestamp(int(exp))}")
            except:
                print(f"ğŸ“… BitiÅŸ: {exp}")
        
        print(f"ğŸ”— BaÄŸlantÄ±: {u_info.get('active_cons', '0')} / {u_info.get('max_connections', '0')}")
        print(f"---------------------\n")
    
    except Exception as e:
        if proxies:
            mark_proxy_result(proxies['http'], success=False)
        print(f"âŒ API hatasÄ±: {e}")

def download_engine(tasks, target_dir):
    if not tasks or tasks == "BACK": 
        return
    
    os.makedirs(target_dir, exist_ok=True)
    session = requests.Session()
    
    total_files = len(tasks)
    completed = 0
    failed = 0
    
    for idx, (url, name) in enumerate(tasks, 1):
        print(f"\n[{idx}/{total_files}] Ä°ÅŸleniyor: {name[:40]}")
        retries = 0
        success = False
        
        while retries < MAX_RETRIES and not success:
            ua = random.choice(load_ua_pool())
            headers = {'User-Agent': ua}
            
            proxies = None
            current_proxy_url = None
            if PROXY_AUTO_ENABLED and PROXY_POOL:
                proxy_info = get_random_working_proxy()
                if proxy_info:
                    proxies = {'http': proxy_info['proxy'], 'https': proxy_info['proxy']}
                    current_proxy_url = proxy_info['proxy']
                    if retries == 0:
                        print(f"ğŸŒ TR Proxy: {proxy_info['ip']}")
            
            try:
                with session.get(url, headers=headers, proxies=proxies, stream=True, timeout=(10, 60)) as r:
                    r.raise_for_status()
                    
                    parsed_path = urlparse(url).path
                    ext = os.path.splitext(parsed_path)[1].lower()
                    
                    if ext not in ['.mp4', '.mkv', '.avi', '.ts', '.flv', '.mov']:
                        ctype = r.headers.get('Content-Type', '').lower()
                        if 'mp4' in ctype:
                            ext = '.mp4'
                        elif 'mp2t' in ctype or 'mpegts' in ctype:
                            ext = '.ts'
                        elif 'matroska' in ctype or 'mkv' in ctype:
                            ext = '.mkv'
                        elif 'x-flv' in ctype:
                            ext = '.flv'
                        else:
                            ext = '.mp4'
                    
                    clean_filename = turkish_to_english_engine(name + ext)
                    path = os.path.join(target_dir, clean_filename)
                    
                    total = int(r.headers.get('content-length', 0))
                    if os.path.exists(path) and os.path.getsize(path) >= total and total > 0:
                        print(f"âœ… Zaten mevcut: {clean_filename}")
                        success = True
                        completed += 1
                        if current_proxy_url:
                            mark_proxy_result(current_proxy_url, success=True)
                        break

                    with open(path, 'wb') as f:
                        with tqdm(
                            total=total, 
                            unit='B', 
                            unit_scale=True, 
                            desc=f"ğŸ¬ {clean_filename[:25]}", 
                            bar_format='{desc}: {percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
                        ) as bar:
                            for chunk in r.iter_content(chunk_size=1024*1024):
                                if chunk:
                                    f.write(chunk)
                                    bar.update(len(chunk))
                    
                    print(f"âœ… TamamlandÄ±: {clean_filename}")
                    success = True
                    completed += 1
                    if current_proxy_url:
                        mark_proxy_result(current_proxy_url, success=True)
                    
            except Exception as e:
                retries += 1
                if current_proxy_url:
                    mark_proxy_result(current_proxy_url, success=False)
                print(f"âš ï¸ Hata ({retries}/{MAX_RETRIES}): {str(e)[:60]}")
                time.sleep(2)
        
        if not success:
            print(f"âŒ Ä°ndirilemedi: {name}")
            failed += 1
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Ä°NDÄ°RME RAPORU")
    print(f"{'='*60}")
    print(f"âœ… BaÅŸarÄ±lÄ±: {completed}/{total_files}")
    print(f"âŒ BaÅŸarÄ±sÄ±z: {failed}/{total_files}")
    print(f"{'='*60}\n")

def folder_cleaner(path):
    """DetaylÄ± raporlama yapan isim dÃ¼zeltme fonksiyonu."""
    if not os.path.exists(path):
        print("âŒ Yol bulunamadÄ±!")
        return
    
    try:
        files = os.listdir(path)
    except PermissionError:
        print("âŒ KlasÃ¶re eriÅŸim izni yok!")
        return
    
    fixed_count = 0
    already_clean = 0
    error_count = 0
    
    print(f"\nğŸ›  {len(files)} dosya denetleniyor...\n")
    
    for f in files:
        old_path = os.path.join(path, f)
        if os.path.isdir(old_path): 
            continue
        
        new_name = turkish_to_english_engine(f)
        
        if f == new_name:
            print(f"âœ… [DÃœZGÃœN]: {f}")
            already_clean += 1
        else:
            try:
                new_path = os.path.join(path, new_name)
                
                if os.path.exists(new_path):
                    base, ext = os.path.splitext(new_name)
                    counter = 1
                    while os.path.exists(new_path):
                        new_name = f"{base}_{counter}{ext}"
                        new_path = os.path.join(path, new_name)
                        counter += 1
                
                os.rename(old_path, new_path)
                print(f"ğŸ”„ [DÃœZELTÄ°LDÄ°]: {f} -> {new_name}")
                fixed_count += 1
            except Exception as e:
                print(f"âŒ [HATA]: {f} ({e})")
                error_count += 1

    print(f"\n{'='*60}")
    print(f"ğŸ“Š Ä°ÅLEM RAPORU")
    print(f"{'='*60}")
    print(f"âœ… Zaten DÃ¼zgÃ¼n: {already_clean}")
    print(f"ğŸ”§ DÃ¼zeltilen: {fixed_count}")
    print(f"âŒ HatalÄ±: {error_count}")
    print(f"ğŸ“‚ Toplam: {len(files)}")
    print(f"{'='*60}\n")

def proxy_status_menu():
    """Proxy durum bilgisi"""
    os.system('cls' if os.name == 'nt' else 'clear')
    print(f"""
{'='*60}
  PROXY SÄ°STEM DURUMU
{'='*60}
ğŸŸ¢ Durum: {'AKTÄ°F' if PROXY_AUTO_ENABLED else 'KAPALI'}
ğŸ“Š Havuz: {len(PROXY_POOL)} TÃ¼rk Proxy
âš¡ Cache: {'Var' if os.path.exists(proxy_cache_file) else 'Yok'}

""")
    
    if PROXY_POOL:
        print("ğŸ† EN HIZLI 5 PROXY:")
        for i, p in enumerate(PROXY_POOL[:5], 1):
            stats = PROXY_STATS.get(p['proxy'], {'success': 0, 'fail': 0})
            print(f"{i}. {p['ip']} - {p['response_time']:.2f}s (âœ…{stats['success']} âŒ{stats['fail']})")
    
    print(f"\n{'='*60}")
    print("1- Proxy Havuzunu Yenile")
    print("2- Proxy Sistemini Kapat/AÃ§")
    print("0- Geri DÃ¶n")
    print(f"{'='*60}")
    
    choice = input("\nSeÃ§im: ").strip()
    
    if choice == '1':
        collect_turkey_proxies()
        input("\nDevam iÃ§in Enter...")
    elif choice == '2':
        global PROXY_AUTO_ENABLED
        PROXY_AUTO_ENABLED = not PROXY_AUTO_ENABLED
        print(f"âœ… Proxy sistemi {'AKTÄ°F' if PROXY_AUTO_ENABLED else 'KAPALI'}!")
        time.sleep(2)

def main_menu():
    global PROXY_AUTO_ENABLED
    
    if PROXY_AUTO_ENABLED and not PROXY_POOL:
        collect_turkey_proxies()
    
    while True:
        os.system('cls' if os.name == 'nt' else 'clear')
        proxy_status = f"ğŸŸ¢ {len(PROXY_POOL)} TR Proxy" if PROXY_AUTO_ENABLED else "ğŸ”´ KapalÄ±"
        print(f"""
{'='*60}
  VOD DOWNLOADER PRO + AUTO TURKEY PROXY
  DESIGN BY PROTON MEDIA
{'='*60}
ğŸŒ Proxy Durumu: {proxy_status}

1- M3U URL GÄ°R (KATEGORÄ° SEÃ‡MELÄ°)
2- M3U DOSYA SEÃ‡ (YEREL)
3- M3U BÄ°LGÄ° KONTROL (URL ANALÄ°Z)
4- USER-AGENT LÄ°STESÄ°NÄ° YENÄ°LE
5- DOSYA Ä°SÄ°MLERÄ°NÄ° DENETLE & DÃœZELT
6- PROXY SÄ°STEM DURUMU & AYARLAR
7- Ã‡IKIÅ
{'='*60}
""")
        choice = input("SeÃ§iminiz: ").strip()

        if choice == '1':
            url = input("\nM3U URL (Geri iÃ§in 0): ").strip()
            if url == '0': 
                continue
            
            target = input("Ä°ndirme Yolu (Enter=Downloads): ").strip() or DOWNLOAD_DIR_DEFAULT
            
            try:
                print("\nâ³ M3U listesi yÃ¼kleniyor...")
                
                proxies = None
                if PROXY_AUTO_ENABLED and PROXY_POOL:
                    proxy_info = get_random_working_proxy()
                    if proxy_info:
                        proxies = {'http': proxy_info['proxy'], 'https': proxy_info['proxy']}
                        print(f"ğŸŒ TR Proxy kullanÄ±lÄ±yor: {proxy_info['ip']}")
                
                response = requests.get(url, proxies=proxies, timeout=20)
                response.raise_for_status()
                content = response.text
                
                cats = parse_m3u_to_categories(content)
                if not cats:
                    print("âŒ M3U iÃ§eriÄŸi bulunamadÄ±!")
                    time.sleep(2)
                    continue
                
                cats = {k:v for k,v in sorted(cats.items())}
                tasks = select_from_categories(cats)
                
                if tasks != "BACK":
                    download_engine(tasks, target)
                    input("\nDevam iÃ§in Enter...")
                    
            except Exception as e:
                print(f"âŒ Hata: {e}")
                time.sleep(3)

        elif choice == '2':
            files = glob.glob("*.m3u")
            if not files: 
                print("âŒ .m3u dosyasÄ± bulunamadÄ±!")
                time.sleep(2)
                continue
            
            print("\n0- GERÄ°")
            for i, f in enumerate(files, 1): 
                print(f"{i}- {f}")
            
            f_idx = input("\nSeÃ§im: ").strip()
            if f_idx == '0': 
                continue
            
            try:
                selected_file = files[int(f_idx)-1]
                target = input("Ä°ndirme Yolu: ").strip() or DOWNLOAD_DIR_DEFAULT
                
                with open(selected_file, 'r', encoding='utf-8', errors='ignore') as f:
                    cats = parse_m3u_to_categories(f.read())
                
                if not cats:
                    print("âŒ M3U iÃ§eriÄŸi bulunamadÄ±!")
                    time.sleep(2)
                    continue
                
                tasks = select_from_categories(cats)
                if tasks != "BACK":
                    download_engine(tasks, target)
                    input("\nDevam iÃ§in Enter...")
                    
            except Exception as e:
                print(f"âŒ Hata: {e}")
                time.sleep(2)

        elif choice == '3':
            url = input("\nAnaliz edilecek URL (Geri iÃ§in 0): ").strip()
            if url != '0': 
                check_m3u_info(url)
            input("\nDevam iÃ§in Enter...")

        elif choice == '4':
            print("\nğŸ”„ User-Agent yenileniyor...")
            load_ua_pool(update=True)
            print("âœ… 40 yeni User-Agent oluÅŸturuldu!")
            time.sleep(2)

        elif choice == '5':
            path = input("\nKlasÃ¶r Yolu (Geri iÃ§in 0): ").strip()
            if path != '0': 
                folder_cleaner(path)
            input("\nDevam iÃ§in Enter...")

        elif choice == '6':
            proxy_status_menu()

        elif choice == '7': 
            print("\nğŸ‘‹ GÃ¶rÃ¼ÅŸmek Ã¼zere!")
            time.sleep(1)
            break
        
        else:
            print("âŒ GeÃ§ersiz seÃ§im!")
            time.sleep(2)

def parse_m3u_to_categories(content):
    categories = {}
    current_cat = "Diger"
    name = ""
    
    for line in content.splitlines():
        line = line.strip()
        if line.startswith('#EXTINF:'):
            cat_match = re.search(r'group-title="([^"]+)"', line)
            current_cat = cat_match.group(1) if cat_match else "Belirtilmemis"
            
            parts = line.split(',', 1)
            name = parts[1].strip() if len(parts) > 1 else "Bilinmeyen"
            
        elif line.startswith('http'):
            if current_cat not in categories: 
                categories[current_cat] = []
            categories[current_cat].append((line, name))
            name = ""
    
    return categories

def select_from_categories(categories):
    cat_names = sorted(list(categories.keys()))
    
    print(f"\n{'='*60}")
    print("M3U KATEGORÄ° LÄ°STESÄ°")
    print(f"{'='*60}")
    print("0- GERÄ° DÃ–N")
    
    for i, cat in enumerate(cat_names, 1):
        print(f"{i}- {cat} [{len(categories[cat])}]")
    
    print(f"{len(cat_names) + 1}- TÃœMÃœNÃœ Ä°NDÄ°R ({sum(len(v) for v in categories.values())})")
    print(f"{'='*60}")
    
    choice = input("\nSeÃ§im: ").strip()
    
    if choice == '0': 
        return "BACK"
    
    try:
        idx = int(choice)
        if idx == len(cat_names) + 1:
            all_tasks = []
            for cat in cat_names:
                all_tasks.extend(categories[cat])
            
            confirm = input(f"\nâš ï¸ {len(all_tasks)} iÃ§erik indirilecek. Emin misiniz? (E/H): ").upper()
            return all_tasks if confirm == 'E' else "BACK"
        
        if 1 <= idx <= len(cat_names):
            return categories[cat_names[idx-1]]
            
    except:
        pass
    
    print("âŒ GeÃ§ersiz seÃ§im!")
    time.sleep(2)
    return "BACK"

if __name__ == "__main__":
    try:
        print("\n" + "="*60)
        print("ğŸš€ VOD DOWNLOADER PRO + AUTO TURKEY PROXY")
        print("   GitHub Actions Build - EXE Version")
        print("="*60)
        print(f"ğŸ“‚ Ã‡alÄ±ÅŸma Dizini: {application_path}")
        print("\nâ³ Sistem baÅŸlatÄ±lÄ±yor...")
        
        # User-Agent havuzunu yÃ¼kle
        load_ua_pool()
        print("âœ… User-Agent havuzu hazÄ±r!")
        
        # Proxy sistemini baÅŸlat
        if PROXY_AUTO_ENABLED:
            print("\nğŸŒ TÃ¼rkiye Proxy Sistemi baÅŸlatÄ±lÄ±yor...")
            print("âš ï¸ Ä°lk baÅŸlatma 1-2 dakika sÃ¼rebilir...")
            success = collect_turkey_proxies()
            
            if not success:
                print("\nâš ï¸ UYARI: Yeterli TÃ¼rk proxy bulunamadÄ±!")
                print("   Muhtemel Sebepler:")
                print("   - Ä°nternet baÄŸlantÄ± sorunu")
                print("   - Proxy kaynaklarÄ±na eriÅŸim engelli")
                print("   - VPN kullanÄ±yorsanÄ±z kapatmayÄ± deneyin")
                choice = input("\nProxy olmadan devam edilsin mi? (E/H): ").strip().upper()
                if choice != 'E':
                    print("âŒ Program kapatÄ±lÄ±yor...")
                    input("Ã‡Ä±kmak iÃ§in Enter...")
                    sys.exit(0)
                PROXY_AUTO_ENABLED = False
        
        print("\nâœ… Sistem hazÄ±r!\n")
        time.sleep(2)
        main_menu()
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ Program kullanÄ±cÄ± tarafÄ±ndan durduruldu.")
        input("Ã‡Ä±kmak iÃ§in Enter...")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ Kritik hata: {e}")
        import traceback
        traceback.print_exc()
        input("\nHata detaylarÄ± yukarÄ±da. Ã‡Ä±kmak iÃ§in Enter...")
        sys.exit(1)
